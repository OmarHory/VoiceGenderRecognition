{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "**NOTE:** This notebook is supposed to be run on local machine. Google Colab can't extract the .tar.gz file, so I will leave it for the user to install the Dataset on the local machine and upload the generated files to Colab.\n",
    "\n",
    "The dataset that is being used in this notebook and the other notebooks is related to speeh recognition, specifically; Gender Classification.\n",
    "\n",
    "[OPENSLR12](http://www.openslr.org/12/) offers a wide variety of open-sourced datasets that can be used. There are two datasets that has been put into use in this notebook: \n",
    "\n",
    "- **train-clean-100.tar.gz:** Training set of 100 hours \"clean\" speech of 6.3 GB in size.\n",
    "\n",
    "- **test-clean.tar.gz**: Test-set that will contain dev-set as well during training; 346 MB in size. Also, Test and dev sets must be from the same distribution.\n",
    "\n",
    "\n",
    "This snippet will get the HTML page and download the required folders; extract them and delete the tar.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, tarfile, io\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Colab\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    os.mkdir('/content/drive/My Drive/Google Colab/Data')\n",
    "    os.mkdir('/content/drive/My Drive/Google Colab/Data/CNN-data')\n",
    "    os.mkdir('/content/drive/My Drive/Google Colab/Data/NN_ML-data')\n",
    "    print('Running on Colab, run this scraper on your local-machine instead, then upload the dataset in google colab; check the Github link for more info.')\n",
    "    path = \"/content/drive/My Drive/Google Colab/Data/data_set.tar.gz\"\n",
    "    directory_path = \"/content/drive/My Drive/Google Colab/Data\"\n",
    "    \n",
    "else:\n",
    "    print('Not running on Colab')\n",
    "    os.mkdir('./Data')\n",
    "    os.mkdir('./Data/CNN-data')\n",
    "    os.mkdir('./Data/NN_ML-data')\n",
    "    path = \"./Data/data_set.tar.gz\"\n",
    "    directory_path = \"./Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the HTML page of the Dataset Website\n",
    "_html = requests.get('http://www.openslr.org/12/')\n",
    "src = _html.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a soup object.\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "#Find all URLs\n",
    "links = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop through the links and get the URLs of the download .tar.gz files\n",
    "for link in links:\n",
    "    if \"100\" in link.text:\n",
    "        _url_train = link.attrs['href']\n",
    "    if \"test-clean\" in link.text:\n",
    "        _url_test = link.attrs['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small file Test .tar.gz to test the Web-scraper.\n",
    "#url = 'https://www.vim.org/scripts/download_script.php?src_id=6273'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_set(data_url, path, directory_path):\n",
    "    \"\"\"\n",
    "    A fuction that downloads the file given the URL and extracts it into a destination folder; then deletes the .tar.gz file.\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_url : str\n",
    "        URL of the downloadable file.\n",
    "        \n",
    "    \"\"\"\n",
    "    r = requests.get(data_url)\n",
    "    \n",
    "    #Change both paths.\n",
    "\n",
    "    \n",
    "    with open(path, 'wb') as file:\n",
    "        file.write(r.content)\n",
    "        tar = tarfile.open(path, \"r:gz\")\n",
    "        tar.extractall(directory_path)\n",
    "        tar.close()\n",
    "        file.close\n",
    "    os.remove(path)\n",
    "    print(\"The dataset .tar.gz is removed and the extracted file is kept.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset .tar.gz is removed and the extracted file is kept.\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "#download_data_set(url, path, directory_path) # If you are on colab this will result in an error while\n",
    "                                             # extracting. Any improvements on how to do such operation is appreciated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset .tar.gz is removed and the extracted file is kept.\n"
     ]
    }
   ],
   "source": [
    "#Download\n",
    "download_data_set(_url_train)\n",
    "download_data_set(_url_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
